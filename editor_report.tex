\documentclass[titlepage,12pt,letterpaper]{article}
\usepackage{amsmath,amscd,amsthm,amsfonts,amssymb,amstext,bbm}
\usepackage{geometry,lscape,graphicx,float,morefloats,pdflscape,accents,microtype}
\usepackage{color,setspace,booktabs,bigstrut,enumerate,hyphenat,lscape,multirow}
\usepackage{epstopdf,fancyhdr,parskip,subcaption,textcomp,srcltx,xcolor,xr}
\usepackage[font={raggedright}, indentfirst=false]{quoting}
\usepackage[titletoc,title]{appendix}
%\usepackage[para,online,flushleft]{threeparttable}
\usepackage[auth-sc,affil-sl]{authblk}
\usepackage[format=hang]{caption}
\usepackage{amsmath}

\externaldocument[paper-]{manuscript_junji_sept2019}

\usepackage{hyperref}
%\definecolor{ultramarine}{RGB}{0,32,96}
\hypersetup{colorlinks=TRUE,citecolor={blue} }
\usepackage[round]{natbib}

\renewcommand{\familydefault}{\rmdefault}
\renewcommand*\rmdefault{cmr}

\linespread{1.3}

\setlength{\parindent}{0.2in}
\newsavebox{\tablebox}

\geometry{left=1in,right=1in,top=1in,bottom=1in}
\setcounter{MaxMatrixCols}{20}
\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}
\fancyhead[L]{}
\fancyhead[C]{}
\fancyhead[R]{}
\fancyfoot[L]{}
\fancyfoot[R]{\thepage}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\numberwithin{equation}{section}



\DeclareMathOperator*{\var}{var}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\cov}{cov}
\DeclareMathOperator*{\plim}{plim}
\DeclareMathOperator*{\diag}{diag}
\DeclareMathOperator*{\median}{median}
\DeclareMathOperator*{\trace}{tr}
\DeclareMathOperator{\vect}{Vec}
\DeclareMathOperator{\MDA}{MDA}
\allowdisplaybreaks

\newtheorem{theorem}{Theorem}
\newtheorem{acknowledgement}{Acknowledgement}
\newtheorem{algorithm}{Algorithm}
\newtheorem{axiom}{Axiom}
\newtheorem{assumption}{Assumption}
\newtheorem{case}{Case}
\newtheorem{claim}{Claim}
\newtheorem{conclusion}{Conclusion}
\newtheorem*{condition}{Condition}
\newtheorem{conjecture}{Conjecture}
\newtheorem{corollary}{Corollary}
\newtheorem{criterion}{Criterion}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
%\newtheorem{exercise}{Exercise}
\newtheorem{lemma}{Lemma}
\newtheorem{notation}{Notation}
\newtheorem{problem}{Problem}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}
\newtheorem{solution}{Solution}
\newtheorem{summary}{Summary}



\bibliographystyle{elsarticle-harv}

\begin{document}

Re:  JAMS-D-20-00090, "Credit Card Fee-Waiving Policy Under Consumer Cognitive Biases"

Dear Mr Xiao,

Thank you for submitting your manuscript, JAMS-D-20-00090, to be considered for publication by JAMS. We have now completed the review process.

Your paper was evaluated by a set of knowledgeable scholars, whose comments are appended at the end of this letter. They had significant concerns, but saw potential in the paper; thus, I asked an expert AE to weigh in and his/her comments are included, as well. After my own careful reading of your paper and the review team's comments, I have decided to invite a revision. However, this would be a major and risky revision as I am not certain that all of the issues raised can be satisfactorily addressed.

In fact, given the magnitude of improvement needed, I should note that this is normally a set of reviews from which I would make a "reject-and-resubmit" decision as it is hard to forecast the eventual outcome. In particular, this is a case where you likely will need to implement a structural model (or at least some type of rigorous propensity score matching) and also provide some sort of lab-based evidence for the mechanisms you propose. Unless you are willing to make such major changes, it would be best to go elsewhere with the paper -- minor polishing of the current paper will not succeed at JAMS. With that said, you have a very strong and fully engaged review team that, should you choose to revise the manuscript accordingly, I would like to keep involved.

In sum, there are a range of issues, from conceptual to empirical, that combine to limit your paper's incremental contribution. However, I am willing to give you the opportunity to revise the paper and attempt to address the issues raised by the review team. The AE has done an excellent job in synthesizing the reviews and isolating the issues that will be most important to address in your revision. Although you should use the AE’s report as a useful roadmap to guide your revision, you should carefully examine all of the reviewers' comments. In order for the revision to meet the publication standards of JAMS, you must be willing to make a concerted effort to build on the many constructive comments and suggestions of the reviewers, as well as satisfactorily address their concerns pertaining to the conceptual and empirical aspects of the paper. When you resubmit, please include a set of responses to the reviewers and to the AE that indicate how you have addressed their comments
in your revision.

Please note that as a matter of editorial philosophy I try to make a decision about the ultimate disposition of a paper as early in the revision process as possible. I believe this is fairer to both authors and reviewers than endless rounds of revision and review that are not progressing toward a publishable paper. For this reason, I will look very carefully at the next revision and the reviewers' evaluations of it and will very likely make a definitive decision about the paper at that point. Therefore, it is very important that you work hard to address the issues raised by the reviewers.

Please inform the Managing Editor Anne Hoekman (jams.man.ed@gmail.com) whether you plan to revise your paper for JAMS, as well as the approximate time frame by which I can look forward to the manuscript's resubmission.  Normally, we expect revisions to be submitted within 3 months after receiving a decision.

Your revision should be submitted at http://jams.edmgr.com/


Your username is: junjixiao

If you forgot your password, you can click the 'Send Login Details' link on the EM Login page at https://www.editorialmanager.com/jams/.

Please click "Author Login" to submit your revision and please make sure to submit editable source files (i.e Word, TeX).

Thank you for submitting your paper to JAMS, and we look forward to hearing from you.

Sincerely,  

Mark Houston, PhD
Co-Editor
Journal of the Academy of Marketing Science



COMMENTS FOR THE AUTHOR:




Area Editor:

The manuscript was reviewed by three highly knowledgeable reviewers. All the reviewers believe that the topic of consumer financial decision-making and multi-part tariff schemes are interesting to both academics and practitioners. They also, however, all agree that there are significant issues with the design and implementation of your research questions for this paper. After thoroughly reading the paper myself, I share their sentiment and concerns. I do not think it is necessary for me to repeat all of the reviewers’ points. They have each done a great job of highlighting the key issues. Instead, let me highlight the more major issues.

What you have here is an example of a multi-part tariff pricing situation. This can be a rather interesting pricing format to empirically test. However, you have a rather specific problem to address in testing it – self-selection bias. Without formally address this problem, it is difficult to put much faith in the results in the main study or in the counterfactual analysis. To address this problem, you would have to consider at least one of 3 approaches – propensity score matching, building a structural model, and/or running experiments (lab and/or field). You did not seem to consider any of those options in your analysis.

\emph{Response}: we may consider to apply the propensity score matching (PSM) method to choose the control group. As for the dynamic issue, I will talk to an expert, Andrew Ching, but this will be beyond the scope of this paper. I will incorporate his comments and feedbacks into our response letter though. 

Your hypotheses lack clarity. In many cases it is not even clear what your hypothesis is trying to test nor how you might carry out a formal empirical test of your hypotheses as they are written. Perhaps it would be useful to look more into the literature related to multi-part tariffs or on consumer financial decision-making to find a stronger theoretical foundation.

\emph{Response}: This is fair enough. Actually, I just wrapped up the hypotheses in a short time. The hypotheses should be based on theory coming from literature. Also, the link between hypotheses and empirical methodology should be elaborated. I would suggest Liyuan to collect literature and polish the hypotheses and I will wrap up the empirical stragegy to test the hypotheses. 

You need to spend some time rethinking your modeling framework if you are interested in explaining customer lifetime value. The CLV literature is fairly methodologically robust, so it would be worthwhile to consider using one of the many methodological frameworks to calculate and model CLV. Another option would be just to model the decision to churn. This would remove some of the hassles that may come with building and implementing CLV models.

\emph{Response}: we can do both. I will review some literature about CLV and see if there are any models that we can follow. 

You are attempting to test a behavioral construct (e.g., overconfidence) purely with secondary data. In order for you to provide a more convincing test, you may need stronger theoretical foundations or go to the lab and test more formally for some process evidence.

\emph{Response}: this may be related to hyperbolic discounting behavior. If either of you have done that, we can follow this direction and undertake a lab experiment. I will suggest Liyin to carry out this experiment at Fudan, considering his expertise, time and budget constraints. 

As mentioned earlier, I suggest you also go through the reviewers’ comments in detail as they each raise finer details that should be considered to improve upon the contribution of your research.


Reviewer #1: I read the paper with great interest as this seems a very relevant application to important decisions in consumers' lives. It seems the key here is to model this phenomenon correctly. This is where my agreement with the paper stops. While I am not a fan of the mindset that everything needs to be a structural model (i.e., structural models are not the hammer for all nails) BUT for this scenario a structural model is needed. Clearly, consumers are forward-looking when making these decisions. They might not make them correctly, but this is a different discussion.

As has been done in the modeling of choice of mobile-phone plans (e.g., Does Uncertainty Matter? Consumer Behavior Under Three-Part Tariffs, with Katja Seim and Bernd Skiera, Marketing Science, 26, 2007.) a structural model is needed to account for consumer's forward looking behavior in making these decisions. Clearly, the choice of a credit card is an endogenous decision and results in selection bias as consumers self-select into different cards. As this is NOT modeled and not even accounted for (maybe some IV method could have been tried), all results are suspect and the counterfactuals meaningless at this point.

So I do not see a way forward that does not involve starting from zero with a new modeling framework and then one doesn't really know what the results would look like.

\emph{Response}: this is a clear gesture that reviewer I will not let it go without seeing a structural model. A PSM will not satisfy him. If both of you agree with a dynamic model, I would suggest to invite another junior coauthor do the work. Considering my time constraint, I am afraid that i am not able to do the job. Without a dynamic model, any moderate revision will be a waste. However, I do not have any candidates for this job at this moment. 


  I must also say I am a bit surprised that a problem that seems the clear definition of selection bias (consumers self-select into different credit cards) doesn't really mention the endogeneity problem at the core of this issue anywhere prominently nor proposes ANY fix for it.

\emph{Response}: I won't be surprised if I am a reviewer for JAMS. 

Reviewer #2: This study focuses on understanding the effects of fee-structure mechanisms on customer retention and customer lifetime value. The authors employ a dataset from a credit card issuer and test their hypotheses using t-tests and a proportional hazard model. The simulation results while using different proposed policies are also presented. I find the topic interesting as it is always a crucial decision for credit card companies to decide what kind of fee structure to use to maximize the firm's bottom line. However, in the paper's current form, the conceptual development is weak and the empirical results are quite exploratory. Below I refer to these issues and make suggestions for improvement.
1. 	The authors assume that only usage forecast affects the card choice decision and that usage regulation affects customer retention (in Figure 1). However, this framework does not fully reflect the consumer's decision process. For example, usage regulation differs depending on the kind of card a customer chooses. From what I understand, card choice is the first step in the decision and then after using the cards, the customer can see whether they met the usage regulation, which will lead the customer to decide whether to churn or stay with the firm. If they decide to stay, they can decide whether to switch to a new card or keep using the same one. These decisions will affect customer lifetime value overall.
2. 	The paper's conceptual contribution involves developing the logic for overconfidence affecting consumers' usage prediction when making the card choice as well as the actual usage behavior. I understand the authors' explanation that cardholders who are overconfident about their spending levels may end up choosing the annual fee plan rather than the upfront fee plan. However, there is no empirical evidence that justifies the conceptualization. For example, consumers may have chosen the annual fee plan due to lack of experience with credit card companies (given the one firm data, there is no information on prior experience). Further, how does this cognitive bias, i.e., overconfidence, affect consumers' usage patterns? Is this about the consumers' overconfidence about their spending level or overconfidence about their memory capability? I think the authors could consider either provide more alternative explanations or tone down on cognitive biases.
3. 	The hypotheses should be rewritten to clearly articulate the constructs and the direction of the relationship being tested. For example, it is not clear what is tested in Hypothesis 1. How does the one sample t-test result of cardholders who spent less than the required fee-waiving level lead to the conclusion that the data rejects H1 (on page 16)? Furthermore, would overconfidence again explain why customers who chose the lump-sum fee card exceeded the required spending level of the annual fee plan?
4. 	While testing the hypotheses (H1, H2a, H2b), some more detail is needed starting with simple statistics. For example,
1) 	Among the people who spent less than the required fee-waiving level, what is the percentage who spent close to the fee-waiving level vs. those who spent significantly below the fee-waiving level (maybe more overconfident people)?
2) 	For H2a, are the consumers categorized as the cardholders who spent more after paying for the annual fee (=1 if yes) if the difference in spending is higher than 0 yuan? How is "remain, no increase in spending" defined in Figure 2? The actual average spending level of the two groups (waived vs. not waived groups) should also be shown.
5. 	On page 16, the authors say "judging from their ex post usage, all such "big spenders" could have been better off if they had chosen the annual-fee plan rather than the upfront fee plan, because they could have avoided the fees. For them, the credit card with an upfront lump-sum fee was not cost minimizing." However, from what I understand, customers who paid the lump-sum fee would never need to pay any annual fee, so looking at only one year of transactions does not fully explain the long-term benefit of the lump-sum fee card. Figure 3 provides evidence that customers who paid the upfront fee card are less likely to churn.
6. 	With respect to the operationalization of "strategically waived" card holders (2*2000/12 (or 5000 for Gold card) in the last month in Table 3), I wonder if this measure accurately captures the customers who strategically use the card to get the fee waived. Other than the two robustness checks provided in Appendix B, the operationalization should show that the level of spending in the last month (or in the last two to three months) exceeds the usual spending level. For example, the authors can compare the spending level in the 12th month and the average spending level until the month before (1st to 11th month). Whether the proportion of spending in the 12th month compared to the total annual spending exceeds a certain percentage (e.g., >30%) can also be considered. If the authors have data on daily transactions, they can use this information to see if customers accelerate their spending pattern toward the end. Making a figure similar to Figure 3 in Drèze and Nunes (2011)
that shows how the interpurchase time changes by the cardholder types would provide further evidence of different spending patterns.  
7. 	I struggled understanding how clumpiness is calculated here and also why this measure is important in this context. Is the inter-event time calculated in months? Can clumpiness be negative (in Table 4)? Compared to the retail setting used for Zhang et al. (2015), in the credit card usage setting, what proportion of customers can be considered clumpy vs. non-clumpy? Why is this measure used other than measures like variance or volatility?
8. 	The final study on counterfactual simulations seemed less informative and made many assumptions. I would recommend that the authors downplay this aspect of the results. For example,
1) 	How does the contribution margin regression result reflect the actual impact of each component? Is there any late payment fee or interest charges that also need to be considered?
2) 	The decision between the volume-based waiver policy vs. the value-based waiver policy is similar to the decision of loyalty program design. For example, Southwest Airlines used to have a frequency-based rewards program (8 round trips, 1 free ticket) but converted to a revenue-based rewards program since 2011. The main reason behind this change is due to the average revenue generated from each transaction, but this is not fully accounted for in the counterfactual simulations of scenarios 1 and 2.



Reviewer #3: Credit Card Fee-Waiving Policy under Consumer Cognitive Biases (JAMS-D-20-00090)

Overall Comments:

In this paper, the authors examine the effect of changing credit card fee-waiving policies on future customer behavior. Specifically, they investigate the effect of two specific fee-waiving policies: (a) a volume based waiver, and (b) allowing customers to choose their credit card after learning about their own purchase behavior. In general, the authors find that the status quo (of levying annual fees) can diminish lifetime value and that the above two fee waiver policies may result in better outcomes (in terms of CLV). In their conceptualization, the authors posit that the negative effect of annual fees may be driven by customers' overconfidence. The paper addresses an area of research that is both interesting and has managerial value. I have several comments pertaining to conceptualization, theory and empirics that the paper needs to address before evaluation for publication. Below, I have outlined these issues and provided some suggestions on how the authors could improve
the manuscript.

Specific comments:

1.	Theory: The authors use the concept of numeric cognition to argue for how volume based waivers would work better than value based ones. The idea being that volume is less cognitively demanding than monetary value. I am not sure this argument is convincing in the context of credit cards where the consumer is already primed to keep track of monetary expenses (the idea of credit limits is based on this). Modifying just the fee waiver structure from value to volume while still keeping all other aspects of the credit card at the monetary value would only increase cognitive demands, right? I understand that the empirical results seem to suggest that there is: but 'process' evidence showing that the mechanism is indeed numeric cognition may be useful here.

2.	Financial waivers: All the customers in the data are originally in the monetary value waiver and were then exposed to the two alternative policies (non-randomly). The non-randomness of the policies may create selection issues. While I understand this cannot be achieved through observational data, perhaps a simple experiment (in addition to the empirical study) might provide more descriptive evidence of policy effectiveness. The dependent variable in the experiments would obviously not be CLV, but some other type of behavior (such as likelihood to increase purchase etc.).

3.	H1: The wording for H1 is very convoluted and hard to follow exactly what is being tested here. Please consider rewording.
Also, related to my comment #1, I am not sure overconfidence (as opposed to forgetting) is the theoretical mechanism here. The authors suggest that overconfidence can lead to forgetting (memory hurdles) which lead to wrong credit card choices. However, there could be so many other factors that lead to forgetting (cognitive overload etc.). Why not simply use memory hurdles as the theory basis for H1? If overconfidence is indeed the theory base, please clearly articulate how the effect elicits itself.

4.	Literature: This research is closely related to prior work on two part tariffs (Ascarza, Lambrecht, and Vilcassim 2018; Iyengar et al. 2011) and needs to do a better job of articulating how exactly this paper contributes to this stream of literature. It looks like all three policies evaluated in this paper (annual fees, volume waiver, and repeated choice) are types of two part tariff pricing strategies. But, Iyengar et al (2011) show that two part tariffs lead to lower retention and usage (and therefore CLV) when compared to other pricing strategies. Isn't this what H2a and H2b are testing. I'm not sure that this is a contribution on its own. What seems more interesting is how the two alternative policies perform in terms of retention and usage. Generally, the authors could juxtapose this research against prior two-part tariff literature and highlight how (under certain conditions/policies) the two part tariffs may not be so bad after all.

5.	Granting customers an experience period (Alternative policy #2): Is the basic idea of this policy the same of a trial sample? That is, the customer is allowed to 'trial' the credit card for a fixed period of time before making a commitment. Please consider elaborating on this.

6.	Ignoring debt and repayment etc: In page 15, the authors state that this research is interested only in the effectiveness of fees and not interest expenses. However, if we want to make claims on overall customer profitability (CLV), then shouldn't we also include purchase behavior at the transaction level (debt) and repayment as well. I would presume that these policies may actually influence the repayment behavior (given that customers may accelerate their purchase behavior due to the policy). This line of inquiry may actually be interesting from a contribution standpoint.

7.	Figure 2: I am not quite following the numbers presented in Figure 2. The chart says that 1,112 customers churned after 13 months when their fees were not waived, which makes sense. However, after 25 months, 2,660 customers churned when their fees were not waived. Was this after their fees were not waived in month 24?

8.	Revenue/Profit model: Traditionally, CLV models include a model of retention (survival model) as well as a revenue/profit model. However, that is missing here. This would allow the authors to make individual CLV predictions (as opposed to aggregate CLV presented in Eq 3). Why not take advantage of the individual data to get individual CLVs? Another option is to use an RFM based method to assess CLV (for e.g. Fader, Hardie, and Lee 2005; Reinartz and Kumar 2000).

9.	Heterogeneity: How is unobserved heterogeneity being controlled in Eq 1? Typically, one could include a gamma distributed random error term within the proportional hazard model to account for this. Also, are there observed controls for credit worthiness or income in the model? This may be an important control as it pertains to whether or not a customer would choose the fee-waive policy or not.

10.	Descriptives: What is the average transaction volume? How many times do the customers actually use the card (on average) during the study period and what is the market share of the focal credit card (vs. other payment options)? Looking at Table 1, the average number of transactions seems like a very small number which may not reflect actual purchase behavior (customers may be using other credit cards for purchases). This missing information may induce bias in the analysis.

References
Ascarza, Eva, Anja Lambrecht, and Naufel Vilcassim (2018), "When Talk is 'Free': The Effect of Tariff Structure on Usage under Two- and Three-Part Tariffs:," Journal of Marketing Research.

Fader, Peter S., Bruce G. S. Hardie, and Ka Lok Lee (2005), "'Counting Your Customers' the Easy Way: An Alternative to the Pareto/NBD Model," Marketing Science, 24 (2), 275-84.

Iyengar, Raghuram, Kamel Jedidi, Skander Essegaier, and Peter J. Danaher (2011), "The Impact of Tariff Structure on Customer Retention, Usage, and Profitability of Access Services," Marketing Science, 30 (5), 820-36.

Reinartz, Werner J. and V. Kumar (2000), "On the Profitability of Long-Life Customers in a Noncontractual Setting: An Empirical Investigation and Implications for Marketing," Journal of Marketing, 64 (4), 17-35.

\end{document}
